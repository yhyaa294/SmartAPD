{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶∫ Smart Safety Vision - YOLOv8 Model Training\n",
    "\n",
    "This notebook guides you through training a custom YOLOv8 model for PPE detection.\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Google Colab (recommended) or local GPU\n",
    "- PPE detection dataset\n",
    "- Ultralytics YOLOv8 installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics roboflow opencv-python matplotlib\n",
    "\n",
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Download Dataset\n",
    "\n",
    "### Option A: Using Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Roboflow\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Initialize Roboflow (get API key from roboflow.com)\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "# Download PPE detection dataset\n",
    "project = rf.workspace(\"your-workspace\").project(\"ppe-detection\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n",
    "\n",
    "print(f\"‚úÖ Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Using Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a custom dataset, organize it in YOLO format:\n",
    "# dataset/\n",
    "#   ‚îú‚îÄ‚îÄ train/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "#   ‚îú‚îÄ‚îÄ valid/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "#   ‚îî‚îÄ‚îÄ data.yaml\n",
    "\n",
    "# Upload your dataset to Colab or specify path\n",
    "dataset_path = \"path/to/your/dataset\"\n",
    "print(f\"Using dataset at: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Create Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml configuration file\n",
    "data_config = {\n",
    "    'path': dataset.location,  # or your dataset_path\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'test': 'test/images',  # optional\n",
    "    'nc': 5,  # number of classes\n",
    "    'names': ['helmet', 'no_helmet', 'vest', 'no_vest', 'person']\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data_config, f)\n",
    "\n",
    "print(\"‚úÖ Data configuration created!\")\n",
    "print(yaml.dump(data_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 nano model (fastest, good for real-time)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Alternative models:\n",
    "# model = YOLO('yolov8s.pt')  # Small - better accuracy\n",
    "# model = YOLO('yolov8m.pt')  # Medium - even better accuracy\n",
    "# model = YOLO('yolov8l.pt')  # Large - best accuracy, slower\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "results = model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=100,              # Number of training epochs\n",
    "    imgsz=640,              # Image size\n",
    "    batch=16,               # Batch size (adjust based on GPU memory)\n",
    "    name='ppe_detection',   # Experiment name\n",
    "    patience=20,            # Early stopping patience\n",
    "    save=True,              # Save checkpoints\n",
    "    device=0,               # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "    workers=8,              # Number of workers\n",
    "    project='runs/detect',  # Project directory\n",
    "    exist_ok=True,          # Overwrite existing project\n",
    "    pretrained=True,        # Use pretrained weights\n",
    "    optimizer='auto',       # Optimizer (auto, SGD, Adam, AdamW)\n",
    "    verbose=True,           # Verbose output\n",
    "    seed=42,                # Random seed\n",
    "    deterministic=True,     # Deterministic training\n",
    "    single_cls=False,       # Train as single-class\n",
    "    rect=False,             # Rectangular training\n",
    "    cos_lr=False,           # Cosine learning rate scheduler\n",
    "    close_mosaic=10,        # Disable mosaic augmentation for final epochs\n",
    "    resume=False,           # Resume training\n",
    "    amp=True,               # Automatic Mixed Precision\n",
    "    fraction=1.0,           # Dataset fraction to train on\n",
    "    profile=False,          # Profile ONNX and TensorRT speeds\n",
    "    # Data augmentation\n",
    "    hsv_h=0.015,           # HSV-Hue augmentation\n",
    "    hsv_s=0.7,             # HSV-Saturation augmentation\n",
    "    hsv_v=0.4,             # HSV-Value augmentation\n",
    "    degrees=0.0,           # Rotation augmentation\n",
    "    translate=0.1,         # Translation augmentation\n",
    "    scale=0.5,             # Scale augmentation\n",
    "    shear=0.0,             # Shear augmentation\n",
    "    perspective=0.0,       # Perspective augmentation\n",
    "    flipud=0.0,            # Vertical flip augmentation\n",
    "    fliplr=0.5,            # Horizontal flip augmentation\n",
    "    mosaic=1.0,            # Mosaic augmentation\n",
    "    mixup=0.0,             # Mixup augmentation\n",
    "    copy_paste=0.0         # Copy-paste augmentation\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "metrics = model.val()\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nüìä Model Performance Metrics:\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "results_dir = 'runs/detect/ppe_detection'\n",
    "\n",
    "# Show results\n",
    "display(Image(filename=f'{results_dir}/results.png', width=800))\n",
    "\n",
    "# Show confusion matrix\n",
    "display(Image(filename=f'{results_dir}/confusion_matrix.png', width=600))\n",
    "\n",
    "# Show validation batch predictions\n",
    "display(Image(filename=f'{results_dir}/val_batch0_pred.jpg', width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test Model on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = YOLO(f'{results_dir}/weights/best.pt')\n",
    "\n",
    "# Test on sample images\n",
    "test_images = ['path/to/test/image1.jpg', 'path/to/test/image2.jpg']\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = best_model(img_path)\n",
    "    \n",
    "    # Display results\n",
    "    for r in results:\n",
    "        im_array = r.plot()  # Plot results\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(im_array[..., ::-1])  # Convert BGR to RGB\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Detection Results: {img_path}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "\n",
    "# 1. ONNX (for faster inference)\n",
    "best_model.export(format='onnx')\n",
    "print(\"‚úÖ Model exported to ONNX\")\n",
    "\n",
    "# 2. TensorRT (for NVIDIA GPUs)\n",
    "# best_model.export(format='engine')\n",
    "\n",
    "# 3. TensorFlow Lite (for mobile)\n",
    "# best_model.export(format='tflite')\n",
    "\n",
    "# 4. CoreML (for iOS)\n",
    "# best_model.export(format='coreml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Google Colab, download the model\n",
    "from google.colab import files\n",
    "\n",
    "# Download best weights\n",
    "files.download(f'{results_dir}/weights/best.pt')\n",
    "\n",
    "print(\"‚úÖ Model downloaded! Upload to your project's models/ folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Performance Optimization Tips\n",
    "\n",
    "### If accuracy is low:\n",
    "1. **Increase epochs**: Train for more epochs (150-200)\n",
    "2. **Use larger model**: Try YOLOv8s or YOLOv8m\n",
    "3. **More data**: Collect more training images\n",
    "4. **Data augmentation**: Increase augmentation parameters\n",
    "5. **Better annotations**: Review and improve label quality\n",
    "\n",
    "### If inference is slow:\n",
    "1. **Use smaller model**: YOLOv8n is fastest\n",
    "2. **Export to ONNX**: Faster inference\n",
    "3. **Reduce image size**: Use 416 or 320 instead of 640\n",
    "4. **Use GPU**: Enable CUDA if available\n",
    "5. **Batch processing**: Process multiple frames together\n",
    "\n",
    "### If memory issues:\n",
    "1. **Reduce batch size**: Try 8 or 4\n",
    "2. **Smaller image size**: Use 416 instead of 640\n",
    "3. **Use gradient accumulation**: Simulate larger batches\n",
    "4. **Close other applications**: Free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "1. Download the `best.pt` file\n",
    "2. Place it in your project's `models/` folder\n",
    "3. Update `config.yaml` with the model path\n",
    "4. Run the main detection system: `python main.py`\n",
    "5. Launch dashboard: `streamlit run dashboard/app.py`\n",
    "\n",
    "Happy detecting! ü¶∫"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
